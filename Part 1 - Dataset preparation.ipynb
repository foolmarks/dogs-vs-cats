{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Dogs-vs-Cats dataset preparation\n",
    "\n",
    "\n",
    "## 1. Downloading the dataset from Kaggle\n",
    "\n",
    "If you are not already registered, go to the [Kaggle website](https://www.kaggle.com) and create an account.\n",
    "\n",
    "Once you are logged in, download the [dogs-vs-cats dataset](https://www.kaggle.com/c/dogs-vs-cats/data) and place the downloaded zip file (dogs-vs-cats.zip) in the same folder as this Jupyter NoteBook.\n",
    "\n",
    "The dogs-vs-cats.zip contains another pair of zip archives - test1.zip contains unlabelled images that were required as part of the orginal Kaggle Challenge, we won't be using them.\n",
    "\n",
    "train.zip contains 25000 labelled images where the filename of the JPEG image indicates its class (or label). For example, `cat.12.jpg` is clearly part of the cat class. We will divide these 25k images into a training set of approximately 19k images, a validation set of approximately 5k images and a test set of approximately 1k images.\n",
    "\n",
    "The training set is, obviously, used during training. The validation set is used to validate accuracy at the end of each training epoch - the validation images are not used to train the model.\n",
    "\n",
    "Finally, the test set is a small set of 'unseen' data that we will use to make predictions with the trained model.\n",
    "\n",
    "\n",
    "## 2. Moving the images into folders\n",
    "\n",
    "We will be using the Keras `.flow_from_directory()` method during training, so the images need to be divided into folders that reflect the classes:\n",
    "<br>\n",
    "\n",
    "![title](img/folders.png)\n",
    "\n",
    "<br>\n",
    "We start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "from random import seed, random\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create some variables that point to the current working directory and to the folders that we want to create.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = os.getcwd()\n",
    "print('This script is located in: ', SCRIPT_DIR)\n",
    "\n",
    "# dataset top level\n",
    "DATASET_DIR = os.path.join(SCRIPT_DIR, 'dataset')\n",
    "\n",
    "# train, validation and test folders\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "VALID_DIR = os.path.join(DATASET_DIR, 'valid')\n",
    "TEST_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "\n",
    "# class folders\n",
    "TRAIN_CAT_DIR = os.path.join(TRAIN_DIR, 'cat')\n",
    "TRAIN_DOG_DIR = os.path.join(TRAIN_DIR, 'dog')\n",
    "VALID_CAT_DIR = os.path.join(VALID_DIR, 'cat')\n",
    "VALID_DOG_DIR = os.path.join(VALID_DIR, 'dog')\n",
    "TEST_CAT_DIR = os.path.join(TEST_DIR, 'cat')\n",
    "TEST_DOG_DIR = os.path.join(TEST_DIR, 'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we delete any previous folders and then make new class folders just like in the image above.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any previous data\n",
    "dir_list = [DATASET_DIR]\n",
    "for dir in dir_list: \n",
    "    if (os.path.exists(dir)):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "    print(\"Directory\" , dir ,  \"created \")\n",
    "    \n",
    "# make all necessary folders\n",
    "dir_list = [VALID_DIR, TEST_DIR,TRAIN_CAT_DIR,TRAIN_DOG_DIR, \\\n",
    "            VALID_CAT_DIR, VALID_DOG_DIR,TEST_CAT_DIR,TEST_DOG_DIR]\n",
    " \n",
    "for dir in dir_list: \n",
    "    os.makedirs(dir)\n",
    "    print(\"Directory \" , dir ,  \"created \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the dogs-vs-cats.zip archive that we downloaded from Kaggle, then unzip the train.zip archive that was inside it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the dogs-vs-cats archive that was downloaded from Kaggle\n",
    "zip_ref = zipfile.ZipFile('./dogs-vs-cats.zip', 'r')\n",
    "zip_ref.extractall('./dataset')\n",
    "zip_ref.close()\n",
    "\n",
    "# unzip train archive (inside the dogs-vs-cats archive)\n",
    "zip_ref = zipfile.ZipFile('./dataset/train.zip', 'r')\n",
    "zip_ref.extractall('./dataset')\n",
    "zip_ref.close()\n",
    "\n",
    "print('Unzipped dataset..')\n",
    "\n",
    "\n",
    "# remove un-needed files\n",
    "os.remove(os.path.join(DATASET_DIR, 'sampleSubmission.csv'))\n",
    "os.remove(os.path.join(DATASET_DIR, 'test1.zip'))\n",
    "os.remove(os.path.join(DATASET_DIR, 'train.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of all 25k images that are now in the `dataset/train` folder.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all files currently in the train folder\n",
    "imageList = list()\n",
    "for (root, name, files) in os.walk(TRAIN_DIR):\n",
    "    imageList += [os.path.join(root, file) for file in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a random number generator which will generate a random floating-point number between 0 and 1 each time we call `random()`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "test_ratio = 0.04\n",
    "valid_ratio = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move the files to their class folders inside the train, validation or test folders based on the random number that we generate. If the random number is less `test_ratio`, the image file will be used for test. If the random number is greater than `test_ratio` but less than `valid_ratio`, the image will be used for validation. Any random number greater than `valid_ratio` means the image will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the images to their class folders inside train, valid, test\n",
    "for img in imageList:\n",
    "    filename = os.path.basename(img)\n",
    "    class_folder,_ = filename.split('.',1)\n",
    "\n",
    "    # choose between train, test, validation based on random number\n",
    "    if random() <= test_ratio:\n",
    "        dst_dir = TEST_DIR\n",
    "    elif (random() > test_ratio and random() <= (test_ratio + valid_ratio)):\n",
    "        dst_dir = VALID_DIR\n",
    "    else:\n",
    "        dst_dir = TRAIN_DIR\n",
    "       \n",
    "    os.rename(img, os.path.join(dst_dir, class_folder, filename))\n",
    "\n",
    "print ('FINISHED CREATING DATASET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all of the data ready for training and can move to the Part 2 Notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
