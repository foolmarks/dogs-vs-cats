{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Dogs-vs-Cats training, validation, predictions and saving\n",
    "\n",
    "We prepared the dataset in the [Part 1 NoteBook](Part1_dataset_prep.ipynb) so that it is compatible with the `.flow_from_directory()` method.\n",
    "\n",
    "Now we are ready to start training. We begin by importing the Keras modules that are required...\n",
    "\n",
    "+ `import Adam` - we will be usng the Adaptive Momentum optimizer.\n",
    "+ `import binary_crossentropy` - there are only two classes, so we can use binary cross-entropy rather than softmax cross-entropy.\n",
    "+ `import TensorBoard, EarlyStopping` - these callback will be used to gather TensorBoard data and to stop training if the validation accuracy no longers increases over a set number of epochs.\n",
    "+ `import ImageDataGenerator` - the ImageDataGenerator will produce batches of augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from customCNN import customCNN\n",
    "\n",
    "\n",
    "# Silence TensorFlow messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up the folders for storing the trained Keras model, the TensorBoard logs and the augmented images and delete any previous results.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = os.getcwd()\n",
    "print('This script is located in: ', SCRIPT_DIR)\n",
    "\n",
    "TRAIN_DIR = os.path.join(SCRIPT_DIR, 'dataset/train')\n",
    "VALID_DIR = os.path.join(SCRIPT_DIR, 'dataset/valid')\n",
    "TEST_DIR = os.path.join(SCRIPT_DIR, 'dataset/test')\n",
    "\n",
    "# Augmented images folder\n",
    "AUG_IMG_DIR = os.path.join(SCRIPT_DIR,'aug_img')\n",
    "\n",
    "# Keras model folder\n",
    "KERAS_MODEL_DIR = os.path.join(SCRIPT_DIR, 'keras_model')\n",
    "\n",
    "# TensorBoard folder\n",
    "TB_LOG_DIR = os.path.join(SCRIPT_DIR, 'tb_logs')\n",
    "\n",
    "# remove previous results and recreate folders\n",
    "dir_list = [KERAS_MODEL_DIR, TB_LOG_DIR, AUG_IMG_DIR]\n",
    " \n",
    "for dir in dir_list: \n",
    "    if (os.path.exists(dir)):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "    print(\"Directory\" , dir ,  \"created \")\n",
    "\n",
    "if (os.path.exists('results.csv')):\n",
    "    os.remove('results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training parameters are set here...note that we are very unlikely to reach 100 epochs due to the Early Stopping callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "# batchsizes for training & validation, batchsize for prediction is 1\n",
    "TRAIN_BATCHSIZE = 64\n",
    "VAL_BATCHSIZE = 64\n",
    "\n",
    "# optimizer learning rate & decay rate\n",
    "LEARN_RATE = 0.0001\n",
    "DECAY_RATE = LEARN_RATE/10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real-time image augmentation includes a resizing of the images. We set the image size to be 200 x 200 pixels. All images will be resized before being used in training, validation and prediction. Note that the orignal images in the Kaggle dataset are of differing sizes and are not usually square. Resizing the images in this way will lead to some distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 200\n",
    "IMAGE_WIDTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of our CNN is contained in the customCNN.py script and uses the Keras Functional API. The CNN is *fully-convolutional* - the dense or fully-connected layers have been replaced with convolutional layers that have their kernel sizes, number of filters and stride lengths set such that they create output shapes that mimic the output shapes of dense/FC layers.\n",
    "\n",
    "There are no pooling layers - these have also been replaced with convolutional layers that have their kernel size and strides set to the same value which is > 1.\n",
    "\n",
    "The output activation layer is a sigmoid function as we only have two classes - if the output of the sigmoid is > 0.5, the predicted class is 'dog', less that 0.5 is a prediction of 'cat'.\n",
    "\n",
    "The CNN has deliberately been kept simple (it only has 8 convolutional layers) so the expected prediction accuracy will not be higher than approximately 90%. To reduce overfitting, batch normalization layers have been used and also L2 kernel regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = customCNN(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "# print a summary of the model\n",
    "print(model.summary())\n",
    "print(\"Model Inputs: {ips}\".format(ips=(model.inputs)))\n",
    "print(\"Model Outputs: {ops}\".format(ops=(model.outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we declare two instances of the ImageDataGenerator class. The first, `datagen_tv`, will perform image augmentation for training and validation. The second, `datagen_p` for prediction.\n",
    "\n",
    "The image augmentation for training and validation is performed on-the-fly and is composed of:\n",
    "\n",
    "+ the 8bit pixel data is normalized from 0:225 to the range 0:1.0\n",
    "+ a random rotation of 5Â° max\n",
    "+ random horizontal flipping i.e flipping about the vertical axis to produce a mirror image.\n",
    "+ random horizontal and vertical shifts of the image by 10% of the image size (200 x 200 in this case).\n",
    "\n",
    "We only use pixel normalization for the prediction augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_tv = ImageDataGenerator(rescale=1/255,\n",
    "                                rotation_range=5,\n",
    "                                horizontal_flip=True,\n",
    "                                height_shift_range=0.1,\n",
    "                                width_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "# data generation for prediction - only rescaling\n",
    "datagen_p = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train generator takes images from the specified directory, applies\n",
    "# a resize to 200x200 with bilinear interpolation.\n",
    "train_generator = datagen_tv.flow_from_directory(TRAIN_DIR,\n",
    "                                                 target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                                 interpolation='bilinear',\n",
    "                                                 batch_size=TRAIN_BATCHSIZE,\n",
    "                                                 class_mode='binary',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=42\n",
    "                                                 )\n",
    "'''\n",
    "uncomment save_to_dir=AUG_IMG_DIR to save the augmented images\n",
    "note that this will take up considerable disk space\n",
    "'''\n",
    "validation_generator = datagen_tv.flow_from_directory(VALID_DIR,\n",
    "                                                      target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                                      interpolation='bilinear',\n",
    "                                                      batch_size=VAL_BATCHSIZE,\n",
    "                                                      class_mode='binary',\n",
    "                                                      shuffle=True,\n",
    "                                                    # save_to_dir=AUG_IMG_DIR\n",
    "                                                      )\n",
    "\n",
    "\n",
    "prediction_generator = datagen_p.flow_from_directory(TEST_DIR,\n",
    "                                                     target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                                     interpolation='bilinear',\n",
    "                                                     batch_size=1,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "##############################################\n",
    "# Compile model\n",
    "##############################################\n",
    "# Adam optimizer to change weights & biases\n",
    "# Loss function is binary crossentropy\n",
    "model.compile(optimizer=Adam(lr=LEARN_RATE, decay=0.0),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up two Callbacks. The first is for collecting TensorBoard data. The second defines a means for halting the training if the validation accuracy stops improving for 5 epochs. Once training stops, the model parameters from the epoch that gave the best results in terms of validation accuracy are restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Tensorboard callback\n",
    "tb_call = TensorBoard(log_dir=TB_LOG_DIR,\n",
    "                      batch_size=TRAIN_BATCHSIZE)\n",
    "\n",
    "earlystop_call = EarlyStopping(monitor='val_binary_accuracy',\n",
    "                               mode='max',\n",
    "                               min_delta=0.0001,\n",
    "                               patience=5,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "\n",
    "callbacks_list = [tb_call, earlystop_call]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of steps in one training epoch\n",
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "\n",
    "# calculate number of steps in one validation epoch\n",
    "val_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "# run training\n",
    "train_history=model.fit_generator(generator=train_generator,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  steps_per_epoch=train_steps,\n",
    "                                  validation_data=validation_generator,\n",
    "                                  validation_steps=val_steps,\n",
    "                                  callbacks=callbacks_list,\n",
    "                                  shuffle=True)\n",
    "\n",
    "\n",
    "print(\"\\nTo open TensorBoard: tensorboard --logdir={dir} --host localhost --port 6006\".format(dir=TB_LOG_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training has finished, we can run a final evaluation using the validation set. The data used comes from the validation generator and we run the complete validation set for 1 epoch. `evaluate_generator` returns the evaluation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(generator=validation_generator,\n",
    "                                  max_queue_size=10,\n",
    "                                  steps=val_steps,\n",
    "                                  verbose=1)\n",
    "\n",
    "print ('Evaluation Loss    : ', scores[0])\n",
    "print ('Evaluation Accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extra, optional step we can make predictions using the trained model. The predict_generator returns a list of predictions that it makes from the data fed to the prediction_generator - the test dataset in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the generator before using it for predictions\n",
    "prediction_generator.reset()\n",
    "\n",
    "# calculate number of steps for prediction\n",
    "predict_steps = prediction_generator.n\n",
    "\n",
    "# predict generator returns a list of all predictions\n",
    "pred = model.predict_generator(generator=prediction_generator,\n",
    "                               steps=predict_steps,\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have a list of labels that match the data sent to the prediction generator, so we need to extract the 'ground truth' labels from the filenames in the test dataset. We do this by first creating a list of the filenames that were used during prediction - it is important to understand that this list will be in the order in which the image files were applied to the prediction generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of image filenames used in prediction\n",
    "filenames = prediction_generator.filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another attribute of the prediction generator, `.class_indices`, will give us a dictionary where the classes are the keys. `{'cat': 0, 'dog': 1}`\n",
    "\n",
    "We then swap the keys and values so that we can use the predictions to index the dictionary and get back the associated class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the .class_indices attribute returns a dictionary with keys = classes\n",
    "labels = (prediction_generator.class_indices)\n",
    "print(labels)\n",
    "\n",
    "# make a new dictionary with keys & values swapped \n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run through the list of predictions and decide f they are 'cat or 'dog'.  The values in the list of predictions come from the sigmoid activation function, so they are floating-point values between 0 and 1.  Any value < 0.5 is class 0 and any value above 0.5 is class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 'labels dictionary to create a list of predictions as strings\n",
    "# predictions is a list of sigmoid outputs\n",
    "# if sigmoid output < 0.5, CNN predicted class 0\n",
    "# if sigmoid output > 0.5, CNN predicted class 1\n",
    "predictions = list()\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] > 0.5:\n",
    "        predictions.append(labels[1])\n",
    "    else:   \n",
    "        predictions.append(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of predictions that are strings (i.e. either 'cat or 'dog') we can compare this list to the ground truth labels (extracted from the filenames) to calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the list of predictions and compare to ground truth labels\n",
    "# ground truth labels are derived from prediction filenames.\n",
    "correct_predictions = 0\n",
    "wrong_predictions = 0\n",
    "\n",
    "for i in range (len(predictions)):\n",
    "\n",
    "    # ground truth is first part of filename (i.e. the class folder)\n",
    "    # will need to be modified to '\\' for windows\n",
    "    ground_truth, _ = filenames[i].split('/',1)\n",
    "\n",
    "    # compare prediction to ground truth\n",
    "    if predictions[i] == ground_truth:\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        wrong_predictions += 1\n",
    "\n",
    "# calculate accuracy\n",
    "acc = (correct_predictions/len(predictions)) * 100\n",
    "\n",
    "print('Correct Predictions: ',correct_predictions)\n",
    "print('Wrong Predictions  : ',wrong_predictions)\n",
    "print('Prediction Accuracy: ',acc,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction results can also be captured in a .csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write filenames and associated predictions to .csv file\n",
    "results = pd.DataFrame({\"Filename\":filenames,\n",
    "                        \"Predictions\":predictions})\n",
    "results.to_csv('results.csv',index=False)\n",
    "\n",
    "print('\\nPredictions and true labels saved to results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model is saved in the directory pointed to by the variable `KERAS_MODEL_DIR`. The model weighst and biases are stored in an HDF5 format file called 'k_model_weights.h5'. The architecture (without weights) is stored in a JSON file called 'k_model_architecture.json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save just the weights (no architecture) to an HDF5 format file\n",
    "model.save_weights(os.path.join(KERAS_MODEL_DIR,'k_model_weights.h5'))\n",
    "\n",
    "# save just the architecture (no weights) to a JSON file\n",
    "with open(os.path.join(KERAS_MODEL_DIR,'k_model_architecture.json'), 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "\n",
    "print('\\nTrained model saved to {dir}'.format(dir=KERAS_MODEL_DIR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
